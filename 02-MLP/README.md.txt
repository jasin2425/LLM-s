SIEĆ DZIAŁĄ NASTĘPUJĄCO

-DLA KAŻDEJ LITERY MAMY ZAPISANĄ JEJ 'LOKALIZACJE' W MACIERZY C, DZIĘKI CZEMU BĘDZIEMY MOGLI SPRAWDZIĆ KTÓRE LITERY WYSTĘPUJĄ ZAMIENNIE

-NASTĘPNIE TWORZYMY MACIERZ EMB KTÓRA BĘDZIE DLA KAŻDEGO INPUTU W ZBIORZE IMION (CZYLI NP Z 3 LITER PRZEWIDUJEMY 4 LITERE) TWORZYMY MACIERZ
'LOKALIZACJI'

-TWORZYMY MACIERZ WAG  KTÓRĄ MNOŻYMY  RAZY EMB.VIEW(-1,6) I BIAS KTÓRY DODAJEMY DO WYNIKU

- ROBIMY Z TEGO TANH

- NASTĘPNIE TWORZYMY LOGITS CZYLI Z WYNIKU TANH MNOZYMY RAZY KOLEJNĄ MACIERZ WAG I DODAJEMY BIAS A NASTĘPNIE Z TEGO ROBIMY SOFTMAX

- I NORMALIZUJEMY WYNIK

- NASTPENIE LICZYMY SREDNI LOG LOSS DLA KAZDEGO OUTPUTU





DODATKI

CZEMU LEPIEJ UZYC FUNKCJI F.CROSS_ENTROPY OD RECZNEGO SOFTMAXA I LICZENIA STRATY?
1. STABILNOŚĆ NUMERYCZNA, SOFTMAX WARIUJE DLA DUŻYCH LICZB DODATNICH
2. OPTYMALIZACJA - _BACKWARD TWORZY ZDECYDOWANIE MNIEJ WĘZŁÓW W GRAFIE OBLICZENIOWYM
3. Optumalizacja - forward pass nie tworzy niepotrzebnych tensorów

JAK SZUKA SIE LEARNING RATE?
szacujemy najmniejsza i najwieksza logicznie możliwa wartość lr(najmniejsza- jeszcze spada loss, największa - loss nie skacze i nie wariuje), następnie
losujemy jakies n wartości z tego i patrzymy jak zachowuje się loss, rysujemy wykres loss od lre i patrzymy gdzie loss jest stabliny i maleje
najlepszy lr - chwile zanim zacznie się robic niestabilny	

DLA DUZYCH ZBIOROW DANYCH W TRENOWANIU UZYWAMY MINIBATCHE

JESLI TRAIN LOSS ~ DEV LOSS ~ TEST LOSS I WYSOKI LOSS TO PRAWDOPODOBNIE SIEC Z MALA  - ZA MALO HIPER PARAMETRO
JESLI TRAIN << TEST TO OVERFITTING  (REGURALIZACJA/MNIEJ PARAMETROW)
JEST TRAIN >>TEST - OVERFIT


